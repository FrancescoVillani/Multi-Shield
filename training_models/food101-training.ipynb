{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ab1176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:03.631126Z",
     "iopub.status.busy": "2023-08-05T15:10:03.630175Z",
     "iopub.status.idle": "2023-08-05T15:10:07.299507Z",
     "shell.execute_reply": "2023-08-05T15:10:07.298495Z"
    },
    "papermill": {
     "duration": 3.678534,
     "end_time": "2023-08-05T15:10:07.302040",
     "exception": false,
     "start_time": "2023-08-05T15:10:03.623506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ingredients.dataset import get_dataset_loaders\n",
    "from ingredients.utilities import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd15b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:11.418081Z",
     "iopub.status.busy": "2023-08-05T15:10:11.417064Z",
     "iopub.status.idle": "2023-08-05T15:10:11.426832Z",
     "shell.execute_reply": "2023-08-05T15:10:11.425960Z"
    },
    "papermill": {
     "duration": 0.018692,
     "end_time": "2023-08-05T15:10:11.428866",
     "exception": false,
     "start_time": "2023-08-05T15:10:11.410174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "\n",
    "config = {\n",
    "    \"seed\": 1123,\n",
    "    \"dataset\": \"food101\",\n",
    "    \"n_samples\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_epochs\": 5, # 40\n",
    "    \"preprocess_forward\": True,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "# resnet50\n",
    "MODEL_FILENAME = f\"resnet18.model_seed={config['seed']}.dataset={config['dataset']}.dataset_seed=1233.pth\"\n",
    "\n",
    "SAVE_MODEL_PATH = \"./pretrained_models\"\n",
    "os.makedirs(SAVE_MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeb0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config[\"seed\"])\n",
    "\n",
    "device = torch.device(config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d08addf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:11.453952Z",
     "iopub.status.busy": "2023-08-05T15:10:11.453131Z",
     "iopub.status.idle": "2023-08-05T15:10:51.814064Z",
     "shell.execute_reply": "2023-08-05T15:10:51.812135Z"
    },
    "papermill": {
     "duration": 40.370003,
     "end_time": "2023-08-05T15:10:51.816239",
     "exception": false,
     "start_time": "2023-08-05T15:10:11.446236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FOOD101 dataset with batch size 64\n",
      "whole length of the validation set is: 25250\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_dataset_loaders(\n",
    "    config[\"dataset\"], config[\"batch_size\"], config[\"n_samples\"], config[\"seed\"]\n",
    ")\n",
    "\n",
    "train_loader = dataloaders[\"train\"]\n",
    "test_loader = dataloaders[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57e6d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:54.047660Z",
     "iopub.status.busy": "2023-08-05T15:10:54.047368Z",
     "iopub.status.idle": "2023-08-05T15:10:54.989247Z",
     "shell.execute_reply": "2023-08-05T15:10:54.988144Z"
    },
    "papermill": {
     "duration": 0.954899,
     "end_time": "2023-08-05T15:10:54.993874",
     "exception": false,
     "start_time": "2023-08-05T15:10:54.038975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazzaro/miniconda3/envs/multishield/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lazzaro/miniconda3/envs/multishield/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-34 model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last layer to output n classes\n",
    "CLASS_NUM = 101\n",
    "\n",
    "num_classes = CLASS_NUM\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_features, num_classes)\n",
    "\n",
    "if config[\"preprocess_forward\"]:\n",
    "    torch_preprocess = transforms.Normalize(\n",
    "                (0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)\n",
    "            )\n",
    "\n",
    "    # MONEKY PATCH FOR PREPROCESSING\n",
    "    original_forward = resnet.forward\n",
    "\n",
    "    def preprocess_forward(x, *args, **kwargs):\n",
    "        x = torch_preprocess(x)\n",
    "        return original_forward(x, *args, **kwargs)\n",
    "\n",
    "    resnet.forward = preprocess_forward\n",
    "\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71a935a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:55.033377Z",
     "iopub.status.busy": "2023-08-05T15:10:55.033059Z",
     "iopub.status.idle": "2023-08-05T15:10:55.041307Z",
     "shell.execute_reply": "2023-08-05T15:10:55.040286Z"
    },
    "papermill": {
     "duration": 0.020567,
     "end_time": "2023-08-05T15:10:55.044537",
     "exception": false,
     "start_time": "2023-08-05T15:10:55.023970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ccf714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:55.062259Z",
     "iopub.status.busy": "2023-08-05T15:10:55.062001Z",
     "iopub.status.idle": "2023-08-05T15:10:55.068646Z",
     "shell.execute_reply": "2023-08-05T15:10:55.067733Z"
    },
    "papermill": {
     "duration": 0.017761,
     "end_time": "2023-08-05T15:10:55.070721",
     "exception": false,
     "start_time": "2023-08-05T15:10:55.052960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#validation function\n",
    "def validate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    for int, data in enumerate(test_dataloader):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        val_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_running_correct += (preds == target).sum().item()\n",
    "    \n",
    "    val_loss = val_running_loss/len(test_dataloader.dataset)\n",
    "    val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n",
    "    \n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530aea2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:55.087886Z",
     "iopub.status.busy": "2023-08-05T15:10:55.087634Z",
     "iopub.status.idle": "2023-08-05T15:10:55.095257Z",
     "shell.execute_reply": "2023-08-05T15:10:55.094272Z"
    },
    "papermill": {
     "duration": 0.018785,
     "end_time": "2023-08-05T15:10:55.097565",
     "exception": false,
     "start_time": "2023-08-05T15:10:55.078780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(model, train_dataloader):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0##this is in train\n",
    "    #for data in tqdm(train_dataloader):\n",
    "    for data in tqdm(train_dataloader, desc=\"Training\", bar_format=\"{l_bar}{bar:30}{r_bar}{bar:-30b}\", leave=False, ncols=100, colour='green', position=0):\n",
    "        \n",
    "        #print(data)\n",
    "        img, labels = data[0].to(device) , data[1].to(device)\n",
    "        optimizer.zero_grad()#train\n",
    "        output = model(img)\n",
    "        loss = criterion(output, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = train_running_loss/len(train_dataloader.dataset)\n",
    "    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n",
    "\n",
    "    #print('Train Loss: %.4f'%train_loss)\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425ec17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:10:55.114793Z",
     "iopub.status.busy": "2023-08-05T15:10:55.114548Z",
     "iopub.status.idle": "2023-08-05T15:13:48.056073Z",
     "shell.execute_reply": "2023-08-05T15:13:48.054706Z"
    },
    "papermill": {
     "duration": 172.952626,
     "end_time": "2023-08-05T15:13:48.058264",
     "exception": false,
     "start_time": "2023-08-05T15:10:55.105638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \u001b[0m\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.087201/  Train Acc : 1.74/  Val Loss : 0.074785/  Val Acc : 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \u001b[0m\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.078711/  Train Acc : 0.00/  Val Loss : 0.072627/  Val Acc : 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \u001b[0m\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m NB_EPOCH \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NB_EPOCH):\n\u001b[0;32m----> 9\u001b[0m     train_epoch_loss, train_epoch_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     val_epoch_loss, val_epoch_accuracy \u001b[38;5;241m=\u001b[39m validate(resnet, test_loader)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m/  Train Acc : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m/  Val Loss : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m/  Val Acc : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(train_epoch_loss,train_epoch_accuracy,val_epoch_loss,val_epoch_accuracy))\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader)\u001b[0m\n\u001b[1;32m      5\u001b[0m train_running_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\u001b[38;5;66;03m##this is in train\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#for data in tqdm(train_dataloader):\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{l_bar}\u001b[39;49;00m\u001b[38;5;132;43;01m{bar:30}\u001b[39;49;00m\u001b[38;5;132;43;01m{r_bar}\u001b[39;49;00m\u001b[38;5;132;43;01m{bar:-30b}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolour\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#print(data)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;43;03m#train\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/multishield/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss , train_accuracy = [], []\n",
    "val_loss , val_accuracy = [], []\n",
    "start = time.time()\n",
    "\n",
    "NB_EPOCH = config[\"num_epochs\"]\n",
    "\n",
    "\n",
    "for epoch in range(NB_EPOCH):\n",
    "    train_epoch_loss, train_epoch_accuracy = train(resnet, train_loader)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(resnet, test_loader)\n",
    "    print(\"Train Loss : %f/  Train Acc : %.2f/  Val Loss : %f/  Val Acc : %.2f\"%(train_epoch_loss,train_epoch_accuracy,val_epoch_loss,val_epoch_accuracy))\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "\n",
    "    #print(\"Train Acc : %f\"%train_accuracy,\"Val Acc : %f\"%val_accuracy)\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(int((end-start)//60), 'minutes', int((end-start)%60), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b51d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# SAVE MODELS\n",
    "# ----------\n",
    "\n",
    "save_path = os.path.join(SAVE_MODEL_PATH, MODEL_FILENAME)\n",
    "\n",
    "torch.save(resnet.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187099d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:13:48.866986Z",
     "iopub.status.busy": "2023-08-05T15:13:48.865818Z",
     "iopub.status.idle": "2023-08-05T15:13:51.824341Z",
     "shell.execute_reply": "2023-08-05T15:13:51.823429Z"
    },
    "papermill": {
     "duration": 3.064705,
     "end_time": "2023-08-05T15:13:51.834653",
     "exception": false,
     "start_time": "2023-08-05T15:13:48.769948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# PLOT\n",
    "# ----------\n",
    "\n",
    "class_names = dataloaders[\"class_names\"]\n",
    "\n",
    "test_dataset = test_loader.dataset\n",
    "\n",
    "ROW = 4\n",
    "COL = 3\n",
    "\n",
    "fig, axs = plt.subplots(nrows = ROW , ncols = COL, figsize=(ROW*4, COL*4))\n",
    "\n",
    "for cnt in range(ROW*COL):\n",
    "    i = random.randrange(0,len(test_dataset))\n",
    "    img = test_dataset[i][0]\n",
    "    label = class_names[test_dataset[i][1]]\n",
    "    \n",
    "    #Get predicted label\n",
    "    with torch.no_grad():\n",
    "        #Use Model\n",
    "        img, _  = test_dataset[i]\n",
    "        img = img.to(device)\n",
    "        outputs = resnet(img.unsqueeze(0))\n",
    "        \n",
    "        #Get the predicted class labels for each images\n",
    "        _ , pred_num = torch.max(outputs.data , dim = 1)\n",
    "        \n",
    "        pred_label = class_names[pred_num]\n",
    "        \n",
    "    axs[(cnt) // COL, (cnt) % COL].imshow(img.cpu().permute(1, 2, 0))\n",
    "    axs[cnt // COL, cnt % COL].set_title(f\"True: {label}\\nPred: {pred_label}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multishield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 241.87957,
   "end_time": "2023-08-05T15:13:55.142952",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-05T15:09:53.263382",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
